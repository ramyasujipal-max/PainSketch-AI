{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8UKD-ZuRZjt",
        "outputId": "4e72868f-4363-4ddb-95e1-00c20f55d4de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install torchvision matplotlib pillow --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageDraw\n",
        "import os\n",
        "import random\n",
        "\n",
        "# Create folders to save the dataset\n",
        "os.makedirs(\"pain_dataset/images\", exist_ok=True)\n",
        "os.makedirs(\"pain_dataset/labels\", exist_ok=True)\n",
        "\n",
        "# Define pain locations (as rough coordinate boxes)\n",
        "pain_regions = {\n",
        "    \"head\": (70, 10, 130, 50),\n",
        "    \"chest\": (60, 60, 140, 120),\n",
        "    \"arm\": (10, 60, 50, 160),\n",
        "    \"leg\": (70, 170, 130, 240)\n",
        "}\n",
        "\n",
        "label_map = {\n",
        "    \"head\": 0,\n",
        "    \"chest\": 1,\n",
        "    \"arm\": 2,\n",
        "    \"leg\": 3\n",
        "}\n",
        "\n",
        "def draw_body_with_pain_mark(region_name, index):\n",
        "    # Create a blank image\n",
        "    img = Image.new(\"RGB\", (200, 250), \"white\")\n",
        "    draw = ImageDraw.Draw(img)\n",
        "\n",
        "    # Draw a stick figure-style body\n",
        "    draw.rectangle([90, 10, 110, 50], fill=\"gray\")  # Head\n",
        "    draw.rectangle([80, 50, 120, 150], fill=\"gray\")  # Torso\n",
        "    draw.rectangle([60, 50, 80, 100], fill=\"gray\")   # Left arm\n",
        "    draw.rectangle([120, 50, 140, 100], fill=\"gray\") # Right arm\n",
        "    draw.rectangle([80, 150, 90, 240], fill=\"gray\")  # Left leg\n",
        "    draw.rectangle([110, 150, 120, 240], fill=\"gray\")# Right leg\n",
        "\n",
        "    # Draw pain mark\n",
        "    box = pain_regions[region_name]\n",
        "    x = random.randint(box[0], box[2])\n",
        "    y = random.randint(box[1], box[3])\n",
        "    draw.ellipse([x-5, y-5, x+5, y+5], fill=\"red\")\n",
        "\n",
        "    # Save image and label\n",
        "    img.save(f\"pain_dataset/images/{index:04d}.png\")\n",
        "    with open(f\"pain_dataset/labels/{index:04d}.txt\", \"w\") as f:\n",
        "        f.write(str(label_map[region_name]))\n",
        "\n",
        "# Generate dataset\n",
        "for i in range(400):\n",
        "    region = random.choice(list(pain_regions.keys()))\n",
        "    draw_body_with_pain_mark(region, i)\n",
        "\n",
        "print(\"✅ Dataset generated: 400 samples with labels.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niurW_bsSDcT",
        "outputId": "09d580b1-05b2-4851-caef-0de9934fa879"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset generated: 400 samples with labels.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Label mapping\n",
        "label_names = [\"head\", \"chest\", \"arm\", \"leg\"]\n",
        "\n",
        "# Image transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Custom dataset\n",
        "class PainSketchDataset(Dataset):\n",
        "    def __init__(self, image_dir, label_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.label_dir = label_dir\n",
        "        self.transform = transform\n",
        "        self.images = sorted(os.listdir(image_dir))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.image_dir, self.images[idx])\n",
        "        label_path = os.path.join(\"pain_dataset/labels\", self.images[idx].replace(\".png\", \".txt\"))\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        with open(label_path, \"r\") as f:\n",
        "            label = int(f.read().strip())\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Load dataset\n",
        "dataset = PainSketchDataset(\"pain_dataset/images\", \"pain_dataset/labels\", transform=transform)\n",
        "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Simple CNN model\n",
        "class PainClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32 * 32 * 32, 128), nn.ReLU(),\n",
        "            nn.Linear(128, 4)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# Initialize\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = PainClassifier().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train loop\n",
        "for epoch in range(5):\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        correct += (outputs.argmax(1) == labels).sum().item()\n",
        "\n",
        "    acc = correct / len(dataset)\n",
        "    print(f\"Epoch {epoch+1} | Loss: {total_loss:.4f} | Accuracy: {acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34ksBZe7SQE5",
        "outputId": "9eebf6da-eed0-47e2-c11f-9d49fe0cfd57"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Loss: 20.6929 | Accuracy: 0.2400\n",
            "Epoch 2 | Loss: 18.0450 | Accuracy: 0.2475\n",
            "Epoch 3 | Loss: 17.6783 | Accuracy: 0.4275\n",
            "Epoch 4 | Loss: 15.6022 | Accuracy: 0.7425\n",
            "Epoch 5 | Loss: 8.7823 | Accuracy: 0.9975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from random import choice\n",
        "from IPython.display import Image as IPyImage, display\n",
        "\n",
        "sample_file = choice(os.listdir(\"pain_dataset/images\"))\n",
        "print(\"Sample image:\", sample_file)\n",
        "\n",
        "display(IPyImage(filename=f\"pain_dataset/images/{sample_file}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "29-POoisTEEw",
        "outputId": "754c85f5-4872-4361-c41a-c2d437a1c11e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample image: 0203.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMgAAAD6CAIAAABriJ9vAAADCklEQVR4nO3dwW6CQBRAUWn8b+TL6aKrWu2ieEGm5+zUkMziMhJN5k3rul7g1T6OXgBjEhYJYZEQFglhkRAWCWGREBYJYZG4Hr2A97Isy5bL53l+1UrOzo5FQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEVCWCSERUJYJIRFQlgkhEViOuOE1Y2nsZ/R6U6Qt2OREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBYJYZEQFglhkRAWCWGREBaJU47u3eLAsb+nG7+7xfXoBfwz0/Tt5bh3ta/CHd1V9fCdUQhrJ/Pt9viDQdsS1h6eVvVlxLaERUJYJIRFQlgkhLWH5feH9xF/zRLWTp62NWJVF2Ht6mdDg1Z18ZfO3sYt6Y4di4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4RTk+/9eQ7qgbNb35Adi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIuEsEgIi4SwSAiLhLBICIvEtK7r0WtgQHYsEsIiISwSwiIhLBLCIiEsEsIi8QnaAyvral7vygAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Use label mapping from before\n",
        "label_names = [\"head\", \"chest\", \"arm\", \"leg\"]\n",
        "\n",
        "# Upload a test image\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Load and transform the uploaded image\n",
        "test_img_path = list(uploaded.keys())[0]\n",
        "test_img = Image.open(test_img_path).convert(\"RGB\")\n",
        "input_tensor = transform(test_img).unsqueeze(0).to(device)\n",
        "\n",
        "# Predict\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output = model(input_tensor)\n",
        "    pred_class = output.argmax(1).item()\n",
        "\n",
        "# Show prediction\n",
        "plt.imshow(test_img)\n",
        "plt.axis('off')\n",
        "plt.title(f\"Predicted Pain Region: {label_names[pred_class]}\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "yAxi7RoUSrsw",
        "outputId": "58bb3154-7293-49de-fb8e-1f2f63a93bcd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-81ecc74e-e9fb-4dff-83ce-10fb0d52842c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-81ecc74e-e9fb-4dff-83ce-10fb0d52842c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving rib.png to rib.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}