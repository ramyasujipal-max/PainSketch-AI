# PainSketch-AI

PainSketch-AI is a PyTorch-based deep learning model that interprets hand-drawn sketches on a body diagram to detect and localize pain areas. Built for **Fusion Hacks 2**, this project aims to help doctors communicate with patients who can't speak or understand the local language.

---

## ğŸ§  Problem Addressed

Many patients struggle to describe pain due to language barriers or medical conditions. PainSketch-AI allows users to simply **draw where it hurts**, and the model identifies the affected region to aid diagnosis.

---

## âš™ï¸ How It Works

1. Users draw pain locations on a digital body diagram.
2. Sketches are preprocessed and fed into a CNN/LSTM model in PyTorch.
3. The model outputs the predicted pain region.

---

## ğŸ“ Files

- `PainSketchAI.ipynb`: The full Colab notebook with model training and prediction.
- `body_template.png`: Transparent body diagram used for user sketches.
- `README.md`: This documentation.

---

## ğŸš€ Tech Stack

- PyTorch
- Google Colab
- Matplotlib/OpenCV
- GitHub

## ğŸ“¸ Sample Output

*(You can add an example image here if you like)*

---

## ğŸ Built For

- [Fusion Hacks 2](https://fusionhacks.devpost.com/) â€” Cross-disciplinary hackathon.

---

## ğŸ™‹â€â™€ï¸ Author

- Ramya Sujipal

